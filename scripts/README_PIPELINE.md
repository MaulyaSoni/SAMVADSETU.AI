# SamvadSetu - Integrated ML Pipeline

## ğŸš€ Overview

This directory contains a **unified, integrated model pipeline** designed for streamlined development and implementation in the next phase.

**Base path:** `d:\Samvad_Setu_final`

---

## ğŸ“‹ Current Structure

### Files in `/scripts`

- **`integrated-model-pipeline.py`** - Main unified module with all model operations (placeholder for next phase)
- **`README_PIPELINE.md`** - This documentation

---

## ğŸ”„ Integrated Model Pipeline

The `integrated-model-pipeline.py` module provides a unified interface for all model-related operations:

### Class: ModelPipeline

```python
from integrated_model_pipeline import ModelPipeline

pipeline = ModelPipeline()
```

### Available Methods (To be implemented in next phase)

#### 1. Data Collection
```python
pipeline.collect_data(gesture_name="hello", count=300)
```
- Captures gesture data via webcam
- Saves preprocessed frames to `raw_data/<gesture_name>/`

#### 2. Data Augmentation
```python
pipeline.augment_data(input_dir="raw_data", output_dir="augmented_data")
```
- Applies transformations: flip, rotation, brightness, scale
- Creates 4x dataset size (1 original + 3 augmented per image)
- Output: `augmented_data/<gesture_name>/`

#### 3. Model Training
```python
pipeline.train_model(epochs=30, batch_size=16)
```
- MobileNetV2 transfer learning
- Frozen base (ImageNet weights) + custom head
- Callbacks: ModelCheckpoint, EarlyStopping
- Output: `data/models/gesture_model.h5`

#### 4. Model Evaluation
```python
pipeline.evaluate_model(test_data_dir="data/test")
```
- Generates classification report
- Creates confusion matrix visualization
- Output: Classification metrics + PNG plot

#### 5. Export to TensorFlow.js
```python
pipeline.export_to_tfjs(output_dir="public/tfjs")
```
- Converts model for browser inference
- Output: `model.json` + weight files in TFJS format

#### 6. Export to ONNX
```python
pipeline.export_to_onnx(output_path="models/gesture_model.onnx")
```
- Exports for cross-platform deployment
- Supports mobile and edge devices

---

## ğŸ“ Project Structure

```
d:\Samvad_Setu_final/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ integrated-model-pipeline.py    â† Main unified module
â”‚   â””â”€â”€ README_PIPELINE.md              â† This file
â”œâ”€â”€ data/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ labels.json                 â† Gesture labels reference
â”œâ”€â”€ public/
â”‚   â””â”€â”€ tfjs/                           â† TFJS models (generated)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ predict/                    â† API endpoint for inference
â”‚   â”œâ”€â”€ recognize/                      â† Real-time recognition UI
â”‚   â”œâ”€â”€ collect/                        â† Data collection UI
â”‚   â””â”€â”€ train/                          â† Training management UI
â””â”€â”€ components/
    â”œâ”€â”€ CameraFeed.tsx                  â† Camera capture
    â”œâ”€â”€ GestureDisplay.tsx              â† Prediction display
    â”œâ”€â”€ WebcamCapture.tsx               â† Webcam component
    â””â”€â”€ ...
```

---

## ğŸ¯ Implementation Plan (Next Phase)

### Phase 1: Core Implementation
- [ ] Implement `collect_data()` with OpenCV webcam capture
- [ ] Implement `augment_data()` with PIL/cv2 transformations
- [ ] Implement `train_model()` with TensorFlow/Keras

### Phase 2: Evaluation & Export
- [ ] Implement `evaluate_model()` with scikit-learn metrics
- [ ] Implement `export_to_tfjs()` with tensorflowjs converter
- [ ] Implement `export_to_onnx()` for edge deployment

### Phase 3: Integration
- [ ] Connect pipeline to Next.js UI components
- [ ] Create API endpoints for each pipeline stage
- [ ] Add progress tracking and error handling

### Phase 4: Optimization
- [ ] Model quantization for faster inference
- [ ] Browser caching for TFJS models
- [ ] Performance benchmarking

---

## ğŸš€ Usage Example (Future)

```python
from integrated_model_pipeline import ModelPipeline

# Initialize pipeline
pipeline = ModelPipeline()

# Step 1: Collect data for multiple gestures
gestures = ["hello", "thanks", "yes", "no", "please", "help", "water", "food", "more"]
for gesture in gestures:
    pipeline.collect_data(gesture_name=gesture, count=300)

# Step 2: Augment dataset
pipeline.augment_data(input_dir="raw_data", output_dir="augmented_data")

# Step 3: Train model
pipeline.train_model(epochs=30, batch_size=16)

# Step 4: Evaluate performance
pipeline.evaluate_model(test_data_dir="data/test")

# Step 5: Export for deployment
pipeline.export_to_tfjs(output_dir="public/tfjs")
pipeline.export_to_onnx(output_path="models/gesture_model.onnx")
```

---

## ğŸ“Š Expected Architecture

### Model Architecture (MobileNetV2 Transfer Learning)

```
Input: 160Ã—160 RGB Image
    â†“
MobileNetV2 Base (ImageNet pre-trained)
    â”œâ”€ Frozen layers (Transfer Learning)
    â””â”€ Last 30 layers fine-tuned
    â†“
GlobalAveragePooling2D
    â†“
Dense(256, ReLU)
    â†“
Dropout(0.3)
    â†“
Dense(N_GESTURES, Softmax)
    â†“
Output: [class1_prob, class2_prob, ..., classN_prob]
```

### Expected Performance

- **Training accuracy:** 95-98%
- **Validation accuracy:** 88-93%
- **Test accuracy (unseen data):** 85-90%
- **Inference time (browser):** 50-200ms per frame
- **Model size:** 10-15 MB (TFJS format)

---

## ğŸ› ï¸ Prerequisites (For Implementation)

### Python Packages
```bash
pip install tensorflow keras opencv-python numpy scikit-learn matplotlib tensorflowjs
```

### Node.js (Optional, for CLI tools)
```bash
npm install -g @tensorflow/tfjs-converter
```

---

## ğŸ“ Data Organization

When implementing `collect_data()`, the structure will be:

```
raw_data/
â”œâ”€â”€ hello/
â”‚   â”œâ”€â”€ frame_0.jpg
â”‚   â”œâ”€â”€ frame_1.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ thanks/
â”‚   â”œâ”€â”€ frame_0.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ ... (9 gesture classes)
```

After augmentation:
```
augmented_data/
â”œâ”€â”€ hello/
â”‚   â”œâ”€â”€ frame_0.jpg          (original)
â”‚   â”œâ”€â”€ frame_0_aug_1.jpg    (augmentation 1)
â”‚   â”œâ”€â”€ frame_0_aug_2.jpg    (augmentation 2)
â”‚   â”œâ”€â”€ frame_0_aug_3.jpg    (augmentation 3)
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

---

## ğŸ” Data Versioning

Keep track of dataset versions for reproducibility:

```json
{
  "version": "1.0",
  "date": "2025-12-08",
  "gestures": 9,
  "samples_per_gesture": 300,
  "augmentation_factor": 4,
  "total_samples": 10800,
  "image_size": "160x160",
  "split": {
    "train": 0.7,
    "val": 0.15,
    "test": 0.15
  }
}
```

---

## ğŸ“š References

- **MobileNetV2:** https://arxiv.org/abs/1801.04381
- **TensorFlow.js:** https://www.tensorflow.org/js/guide
- **Transfer Learning:** https://cs231n.github.io/transfer-learning/
- **Gesture Recognition:** https://github.com/tensorflow/models/tree/master/research/object_detection

---

## âœ… Cleanup Summary

### Removed (December 8, 2025)

- âŒ `collect_dataset_webcam.py` - Integrated into pipeline module
- âŒ `augment_data.py` - Integrated into pipeline module
- âŒ `train_cnn_mobilenet.py` - Integrated into pipeline module
- âŒ `train_cnn.py` - Integrated into pipeline module
- âŒ `train_gesture_model.py` - Integrated into pipeline module
- âŒ `evaluate_model.py` - Integrated into pipeline module
- âŒ `export_tfjs.py` - Integrated into pipeline module
- âŒ `direct_export.py` - Integrated into pipeline module
- âŒ `dataset_builder.py` - Integrated into pipeline module
- âŒ `collect_data.py` - Integrated into pipeline module
- âŒ `/raw_data/` directory - Cleaned up
- âŒ `/augmented_data/` directory - Cleaned up
- âŒ Model files (.h5, evaluation PNG) - Removed for next phase

### Kept

- âœ… `integrated-model-pipeline.py` - Unified module for all ML operations
- âœ… `README_PIPELINE.md` - Documentation
- âœ… `data/models/labels.json` - Reference for gesture labels
- âœ… All web components - Fully functional Next.js UI

---

## ğŸ“ Getting Started

1. **Review** this documentation
2. **Understand** the `integrated-model-pipeline.py` module structure
3. **Implement** each method according to the specification
4. **Test** each component independently
5. **Integrate** with the Next.js API (`app/api/predict/route.ts`)
6. **Deploy** and monitor performance

---

**Last Updated:** December 8, 2025  
**Status:** âœ… Project structure cleaned and ready for next phase
