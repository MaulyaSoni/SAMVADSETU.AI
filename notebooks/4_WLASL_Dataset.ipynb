{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48090f5-4425-4d5c-84e4-99676202156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9906babe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total JSON entries: 2000\n"
     ]
    }
   ],
   "source": [
    "json_path = r\"D:\\Samvad_Setu_final\\datasets\\WLASL\\WLASL_v0.3.json\"\n",
    "\n",
    "with open(json_path, \"r\") as f:\n",
    "    wlasl_meta = json.load(f)\n",
    "\n",
    "print(\"Total JSON entries:\", len(wlasl_meta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0d3437-7652-4ee8-871d-713459f63dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 2000\n",
      "Total mapped videos: 21083\n"
     ]
    }
   ],
   "source": [
    "video_labels = {}\n",
    "class_to_idx = {}\n",
    "idx_counter = 0\n",
    "\n",
    "for item in wlasl_meta:\n",
    "    label = item[\"gloss\"]\n",
    "    \n",
    "    if label not in class_to_idx:\n",
    "        class_to_idx[label] = idx_counter\n",
    "        idx_counter += 1\n",
    "    \n",
    "    for inst in item[\"instances\"]:\n",
    "        vid = inst[\"video_id\"]\n",
    "        subset = inst.get(\"subset\", \"unknown\")  # default if missing\n",
    "        \n",
    "        video_labels[vid] = {\n",
    "            \"subset\": subset,\n",
    "            \"label\": class_to_idx[label]\n",
    "        }\n",
    "\n",
    "print(\"Total classes:\", len(class_to_idx))\n",
    "print(\"Total mapped videos:\", len(video_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52c32d3-603d-4566-8245-b8da3172526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = r\"D:\\Samvad_Setu_final\\datasets\\WLASL\\videos\"\n",
    "\n",
    "def load_frames(path, max_frames=16, resize=(112,112)):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # sample frames uniformly\n",
    "    ids = np.linspace(0, total-1, max_frames).astype(int)\n",
    "\n",
    "    for i in ids:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < max_frames:\n",
    "        return None\n",
    "    \n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b62cf67-4f78-4f63-b839-314a961c8c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total video files in folder: 9659\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = [], []\n",
    "X_val, y_val = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "all_videos = glob(os.path.join(VIDEO_PATH, \"*.mp4\"))\n",
    "print(\"Total video files in folder:\", len(all_videos))\n",
    "\n",
    "for vid in all_videos:\n",
    "    vidname = os.path.basename(vid).split(\".\")[0]  # \"00335\"\n",
    "\n",
    "    if vidname not in video_labels:\n",
    "        continue\n",
    "\n",
    "    info = video_labels[vidname]\n",
    "    subset = info[\"subset\"]\n",
    "    label = info[\"label\"]\n",
    "\n",
    "    frames = load_frames(vid)\n",
    "    if frames is None:\n",
    "        continue\n",
    "\n",
    "    if subset == \"train\":\n",
    "        X_train.append(frames)\n",
    "        y_train.append(label)\n",
    "    elif subset == \"val\":\n",
    "        X_val.append(frames)\n",
    "        y_val.append(label)\n",
    "    else:  # test\n",
    "        X_test.append(frames)\n",
    "        y_test.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecce14-f4f3-485b-8f10-cc7a7ffc24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f109a01-5d07-485b-980c-9696092848eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list_train = []\n",
    "video_list_val = []\n",
    "video_list_test = []\n",
    "\n",
    "all_videos = glob(os.path.join(VIDEO_PATH, \"*.mp4\"))\n",
    "print(\"Total video files in folder:\", len(all_videos))\n",
    "\n",
    "for vid in all_videos:\n",
    "    vidname = os.path.basename(vid).split(\".\")[0]\n",
    "\n",
    "    if vidname not in video_labels:\n",
    "        continue\n",
    "\n",
    "    subset = video_labels[vidname][\"subset\"]\n",
    "    label = video_labels[vidname][\"label\"]\n",
    "\n",
    "    if subset == \"train\":\n",
    "        video_list_train.append((vid, label))\n",
    "    elif subset == \"val\":\n",
    "        video_list_val.append((vid, label))\n",
    "    else:\n",
    "        video_list_test.append((vid, label))\n",
    "\n",
    "print(\n",
    "    \"Train:\", len(video_list_train),\n",
    "    \"Val:\", len(video_list_val),\n",
    "    \"Test:\", len(video_list_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf037186-3957-43b7-9989-2fb3c648c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class WLASLGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, video_list, batch_size=4, max_frames=16, shuffle=True):\n",
    "        self.video_list = video_list\n",
    "        self.batch_size = batch_size\n",
    "        self.max_frames = max_frames\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.video_list)\n",
    "\n",
    "    def load_video(self, path):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        ids = np.linspace(0, max(total-1, 0), self.max_frames).astype(int)\n",
    "\n",
    "        frames = []\n",
    "        for i in ids:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                frame = cv2.resize(frame, (112,112))\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frames.append(frame)\n",
    "        cap.release()\n",
    "\n",
    "        if len(frames) < self.max_frames:\n",
    "            frames += [frames[-1]] * (self.max_frames - len(frames))\n",
    "\n",
    "        return np.array(frames) / 255.0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.video_list[idx*self.batch_size : (idx+1)*self.batch_size]\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for path, label in batch:\n",
    "            X.append(self.load_video(path))\n",
    "            y.append(label)\n",
    "\n",
    "        return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c55e0c-4932-4d37-b05a-a8740fa22dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = WLASLGenerator(video_list_train, batch_size=4, max_frames=16)\n",
    "val_gen   = WLASLGenerator(video_list_val, batch_size=4, max_frames=16)\n",
    "test_gen  = WLASLGenerator(video_list_test, batch_size=4, max_frames=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ae348-c478-4fcc-8b93-3663663479a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1d1a8-5e63-4b54-a4bd-8ea9be97c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_val   = X_val / 255.0\n",
    "X_test  = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea865a8-c48a-495d-acfa-c7df11ef45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv3D(32, (3,3,3), activation='relu', padding='same', input_shape=(16,112,112,3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D((1,2,2)),\n",
    "\n",
    "    Conv3D(64, (3,3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D((2,2,2)),\n",
    "\n",
    "    Conv3D(128, (3,3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D((2,2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(class_to_idx), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a248062c-f628-4bbb-872e-8ad89b30826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32116f4-82df-440b-a348-7ba50b4ee11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f65054-8453-45ae-a16b-a1eecad7e924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450565c-93f3-465a-9ce6-4ad4b3a543c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a68bcbf-69ff-4286-96b2-ca6a8b0c6cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddcf6fb-3ac9-4ba6-98be-0b3cc18b68de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc43983-9ca5-47c8-9bf1-5dfe5234b530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5facc20c-ff28-449b-81b6-cfb2640c1797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcece95-e3e6-4940-8182-8f1e9e1ad852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e03b6-6ada-432e-80fb-e7b5aa751ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101ac27-c216-45f1-9889-9a74312495bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06162433-a0c9-475c-a6de-5ac96c2e4ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264d67f-8762-4536-8557-219c052dd185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e800e-2a1b-450e-a974-21cfa5fda820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video_frames(video_path, max_frames=16, resize=(112,112)):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_ids = np.linspace(0, total_frames-1, max_frames).astype(int)\n",
    "\n",
    "    for fid in frame_ids:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea65bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "labels = []\n",
    "\n",
    "label_folders = sorted(os.listdir(DATASET_PATH))\n",
    "\n",
    "print(\"Total classes found:\", len(label_folders))\n",
    "\n",
    "for idx, label in enumerate(label_folders):\n",
    "    folder_path = os.path.join(DATASET_PATH, label)\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    \n",
    "    for vid in glob(folder_path + \"/*.mp4\"):\n",
    "        frames = load_video_frames(vid)\n",
    "        if frames.shape[0] == 16:\n",
    "            videos.append(frames)\n",
    "            labels.append(idx)\n",
    "\n",
    "videos = np.array(videos)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Total videos loaded:\", videos.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9503bd56-e06d-42e5-964f-c7815be7fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root = r\"D:\\Samvad_Setu_final\\datasets\\WLASL\\videos\"\n",
    "\n",
    "print(\"Exists:\", os.path.exists(root))\n",
    "print(\"\\nItems inside root folder:\")\n",
    "items = os.listdir(root)\n",
    "print(len(items))\n",
    "print(items[:20])  # show first 20 items\n",
    "\n",
    "# Check if folders contain videos\n",
    "count_videos = 0\n",
    "for dirpath, _, filenames in os.walk(root):\n",
    "    for f in filenames:\n",
    "        if f.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
    "            count_videos += 1\n",
    "\n",
    "print(\"\\nTotal video files found:\", count_videos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5cced-5c1d-42cf-877d-1043ee4da806",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = videos.astype(\"float32\") / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35376041-520d-4410-b714-d82e416b52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(videos, labels, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test     = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452f756-70f8-4ea9-9a61-163419d98185",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "\n",
    "    Conv3D(32, (3,3,3), activation='relu', padding='same', input_shape=(16,112,112,3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D((1,2,2)),\n",
    "\n",
    "    Conv3D(64, (3,3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D((2,2,2)),\n",
    "\n",
    "    Conv3D(128, (3,3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D((2,2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(len(label_folders), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9dae10-7079-4d2a-a9eb-ff8515a8fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35687070-1a2f-47d1-89bf-f4904dd48228",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=25,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stop, lr_reduce]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49559f4a-2548-4f3e-ba8d-fed10c156e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc26df8-bdae-4230-8cf7-cb7cbe979958",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(X_test))\n",
    "sample = X_test[idx]\n",
    "\n",
    "pred = model.predict(sample[np.newaxis, ...])\n",
    "pred_class = np.argmax(pred)\n",
    "\n",
    "print(\"Predicted Label:\", label_folders[pred_class])\n",
    "print(\"Actual Label:\", label_folders[y_test[idx]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ce34a-bf15-4702-800b-92de9aa8c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "for i in range(8):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.imshow(sample[i])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c2260-dd58-4bf8-bc72-9d03a8ffb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"wlasl_sign_model_3dcnn.h5\")\n",
    "print(\"Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a4a99-9c8a-42a1-bc69-ab02b22461c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9312997-7317-4198-8e77-20524286bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def capture_and_predict():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frames = []\n",
    "\n",
    "    while len(frames) < 16:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        f = cv2.resize(frame, (112,112))\n",
    "        f = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(f)\n",
    "        cv2.imshow(\"Recording Frames...\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if len(frames) == 16:\n",
    "        frames = np.array(frames).astype(\"float32\")/255.0\n",
    "        pred = model.predict(frames[np.newaxis,...])\n",
    "        cls = np.argmax(pred)\n",
    "        print(\"Predicted Sign:\", label_folders[cls])\n",
    "    else:\n",
    "        print(\"Not enough frames captured.\")\n",
    "\n",
    "capture_and_predict()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
