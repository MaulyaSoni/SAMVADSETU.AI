{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d48d694",
   "metadata": {},
   "source": [
    "# HaGRID Dataset - Hand Gesture Recognition in Real-world Environments\n",
    "\n",
    "**Dataset:** HaGRID by Kaggle (kapitanua/hagrid)  \n",
    "**Size:** 500k+ images of hand gestures in diverse environments  \n",
    "**Classes:** 18 hand gestures (ok, peace, thumbs_up, thumbs_down, fist, palm, etc.)  \n",
    "**Format:** PNG images with JSON annotations (hand bounding boxes)  \n",
    "**Challenge:** Real-world backgrounds, various hand sizes and orientations  \n",
    "**Goal:** Train robust MobileNet/EfficientNet model for practical deployment\n",
    "\n",
    "**Best Run On:** Google Colab with GPU (large dataset)  \n",
    "**Training Time:** 20-40 minutes on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import subprocess, sys\n",
    "packages = ['tensorflow', 'kaggle', 'opencv-python', 'pillow', 'numpy', 'matplotlib', 'scikit-learn', 'tensorflowjs']\n",
    "for pkg in packages:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--quiet', pkg])\n",
    "\n",
    "from pathlib import Path\n",
    "for d in ['external_data', 'datasets', 'models', 'output']:\n",
    "    Path(d).mkdir(parents=True, exist_ok=True)\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f879b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download HaGRID dataset\n",
    "import os\n",
    "\n",
    "# Kaggle download\n",
    "# os.system('kaggle datasets download -d kapitanua/hagrid -p external_data --unzip')\n",
    "\n",
    "# Classes to download (18 gestures)\n",
    "HAGRID_CLASSES = [\n",
    "    'ok', 'peace', 'thumbs_up', 'thumbs_down', 'fist', 'palm', \n",
    "    'call', 'rock', 'stop', 'no_gesture', 'mute', 'dislike',\n",
    "    'like', 'pointing_up', 'pointing_down', 'pointing_left', 'pointing_right', 'closed_fist'\n",
    "]\n",
    "\n",
    "print(\"✓ HaGRID dataset configuration\")\n",
    "print(f\"  Classes: {len(HAGRID_CLASSES)}\")\n",
    "print(f\"  To download: Configure Kaggle API and uncomment os.system() above\")\n",
    "print(f\"  Dataset: https://www.kaggle.com/datasets/kapitanua/hagrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess HaGRID with hand detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def preprocess_hagrid(src_dir='external_data/hagrid', dst_dir='datasets/hagrid', img_size=160):\n",
    "    \"\"\"Extract hand regions and save as uniform-size images.\"\"\"\n",
    "    src = Path(src_dir)\n",
    "    dst = Path(dst_dir)\n",
    "    \n",
    "    if not src.exists():\n",
    "        print(f\"⚠ HaGRID directory not found\")\n",
    "        return\n",
    "    \n",
    "    success = 0\n",
    "    for gesture_dir in src.iterdir():\n",
    "        if not gesture_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        gesture = gesture_dir.name\n",
    "        dst_gesture = dst / gesture\n",
    "        dst_gesture.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process images in gesture folder\n",
    "        for img_file in gesture_dir.glob('*.png'):\n",
    "            try:\n",
    "                # Load image\n",
    "                img = cv2.imread(str(img_file))\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                # Resize to uniform size\n",
    "                img_resized = cv2.resize(img, (img_size, img_size))\n",
    "                \n",
    "                # Save\n",
    "                cv2.imwrite(str(dst_gesture / img_file.name), img_resized)\n",
    "                success += 1\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"✓ Preprocessed {success} HaGRID images\")\n",
    "\n",
    "preprocess_hagrid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EfficientNetB0 on HaGRID\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "\n",
    "IMG_SIZE = 160\n",
    "BATCH = 32\n",
    "EPOCHS = 20\n",
    "DATA_DIR = 'datasets/hagrid'\n",
    "\n",
    "if not os.path.exists(DATA_DIR) or len(os.listdir(DATA_DIR)) == 0:\n",
    "    print(\"⚠ HaGRID dataset not found\")\n",
    "else:\n",
    "    # Data generators\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.15,\n",
    "        validation_split=0.15\n",
    "    )\n",
    "    \n",
    "    train_flow = datagen.flow_from_directory(DATA_DIR, target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                            batch_size=BATCH, subset='training', class_mode='categorical')\n",
    "    val_flow = datagen.flow_from_directory(DATA_DIR, target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                          batch_size=BATCH, subset='validation', class_mode='categorical')\n",
    "    \n",
    "    # Build EfficientNetB0 model\n",
    "    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    base.trainable = False\n",
    "    \n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    outputs = Dense(train_flow.num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base.input, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(train_flow, validation_data=val_flow, epochs=EPOCHS, verbose=1)\n",
    "    model.save('models/hagrid_efficientnet.h5')\n",
    "    print(\"✓ Model trained and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and export HaGRID model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(history.history['accuracy'], label='Train')\n",
    "ax1.plot(history.history['val_accuracy'], label='Val')\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['loss'], label='Train')\n",
    "ax2.plot(history.history['val_loss'], label='Val')\n",
    "ax2.set_title('Loss')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/hagrid_training.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "# Export\n",
    "tfjs.converters.save_keras_model(model, 'output/tfjs_hagrid')\n",
    "print(\"✓ Model exported to output/tfjs_hagrid/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
