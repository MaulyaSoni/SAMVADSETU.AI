# VS Code Notebook Execution Guide

## ğŸ¯ Your Notebook is Ready!

The ASL Alphabet notebook is now properly configured in VS Code with:
- âœ… All dependencies installed
- âœ… TensorFlow 2.19.0 (compatible)
- âœ… Python 3.12.12
- âœ… 20 cells ready to execute

---

## ğŸ“‹ How to Run (Step-by-Step)

### Step 1: Open the Notebook
```
File â†’ Open File
â†’ Select: notebooks/1_ASL_Alphabet_Dataset.ipynb
```

### Step 2: Select Python Kernel
- **Top right:** Look for "Select Kernel" button
- **Click** â†’ Choose "Python 3.12.12" (or your active Python)
- **Wait** for kernel to initialize (takes 5-10 seconds)

### Step 3: Run Cells One by One

**Method A: Using the Play Button** â–¶ï¸
1. Click on any cell
2. Click the **â–¶ï¸ Play** button (top-left of cell)
3. Wait for execution to complete
4. Move to next cell

**Method B: Using Keyboard Shortcut** âŒ¨ï¸
1. Click on any cell
2. Press **Ctrl + Enter** (or Cmd + Enter on Mac)
3. Wait for execution
4. Press **â†“** arrow to move to next cell
5. Repeat

**Method C: Run All Cells** (âš ï¸ For short notebooks only)
- Menu â†’ Run â†’ Run All Cells
- âš ï¸ Not recommended for this notebook (training takes time)

---

## ğŸ”„ Execution Flow

### Phase 1: Setup (2-3 minutes)
```
Cell 0: Import libraries        âœ“ ~1 second
  â†“
Cell 1: Python/TensorFlow check âœ“ ~3 seconds
  â†“
Cell 2: GPU setup               âœ“ ~1 second
  â†“
Cell 3: Kaggle configuration    âœ“ ~1 second
  â†“
Cell 4: Dataset download setup  âœ“ ~1 second
```

**What you'll see:**
```
âœ“ Core libraries imported successfully
Python 3.12.12
TensorFlow 2.19.0
âœ“ Running in Google Colab
GPUs detected: 0
âš  No GPU detected â€” training will be slower on CPU
```

### Phase 2: Data Preparation (10 minutes - only if downloading dataset)
```
Cell 5: Verify dataset          â³ ~1 second
  â†“
Cell 6: Configuration params    âœ“ ~1 second
  â†“
Cell 7: tf.data pipeline        â³ Depends on dataset size
  â†“
Cell 8: Data augmentation       âœ“ ~1 second
  â†“
Cell 9: Model building          âœ“ ~5 seconds
```

**Note:** If dataset not present locally, you must:
1. Download manually from: https://www.kaggle.com/datasets/grassknoted/asl-alphabet
2. Extract to: `external_data/asl_alphabet/`
3. Then run Cell 7+

### Phase 3: Training (30-40 minutes on CPU, 20-30 min on GPU)
```
Cell 10: Compile model          âœ“ ~2 seconds
   â†“
Cell 11: STAGE 1 training       â³ 5-10 minutes (8 epochs)
   â†“
Cell 12: STAGE 2 fine-tuning    â³ 15-30 minutes (25 epochs)
```

**Watch for:**
```
Epoch 1/8
120/120 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 150ms/step - accuracy: 0.4521 - loss: 1.8234
                               - val_accuracy: 0.6123 - val_loss: 1.1245

Epoch 2/8
120/120 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 140ms/step - accuracy: 0.7234 - loss: 0.8156
...
```

### Phase 4: Evaluation (5 minutes)
```
Cell 13: Plot training history  âœ“ ~2 seconds + plot display
   â†“
Cell 14: Validation metrics     âœ“ ~30 seconds
   â†“
Cell 15: Confusion matrix       âœ“ ~2 seconds + plot display
   â†“
Cell 16: Save H5 model          âœ“ ~10 seconds
   â†“
Cell 17: Export SavedModel      âœ“ ~5 seconds
```

### Phase 5: Documentation (Optional)
```
Cell 18: Browser inference (JS) ğŸ“– Reference code
Cell 19: Production tips        ğŸ“– Reference guide
Cell 20: Deployment summary     âœ“ Final status check
```

---

## â±ï¸ Time Estimates

### If running on CPU (local machine)
| Phase | Duration | Action |
|-------|----------|--------|
| Setup | 5 sec | Just wait |
| Data prep | 10 min | If downloading dataset |
| Training | 45-60 min | Go get coffee â˜• |
| Evaluation | 5 min | Watch results |
| **Total** | **~1 hour** | Budget time accordingly |

### If running on GPU (Google Colab)
| Phase | Duration | Action |
|-------|----------|--------|
| Setup | 5 sec | Just wait |
| Data prep | 5 min | Faster download |
| Training | 20-30 min | Go get snack ğŸª |
| Evaluation | 2 min | Quick analysis |
| **Total** | **~30 min** | Much faster! |

---

## ğŸ”´ What to Watch For (Errors)

### Error: "Module not found: tensorflow"
**Cause:** Kernel not using correct Python environment
**Fix:** 
1. Select Kernel â†’ Choose Python 3.12.12
2. Restart Kernel (top right menu)
3. Run Cell 1 again

### Error: "No GPU detected"
**Cause:** Running on CPU (expected locally)
**Fix:** 
- If you need GPU: Copy to Google Colab and run there
- If local training acceptable: Continue with CPU (will be slower)

### Error: "Dataset not found"
**Cause:** Kaggle dataset not downloaded
**Fix:**
1. Download manually: https://www.kaggle.com/datasets/grassknoted/asl-alphabet
2. Extract to: `D:\Samvad_Setu_final\external_data\asl_alphabet\`
3. Run Cell 7 again

### Error: "Out of memory"
**Cause:** Batch size too large for your system
**Fix:**
1. Edit Cell 6: Change `"BATCH_SIZE": 64` â†’ `32`
2. Restart kernel
3. Run cells again

---

## ğŸ“Š Expected Outputs

### After Cell 11 (STAGE 1):
```
âœ“ Stage 1 complete
Best validation accuracy: 0.7234
```

### After Cell 12 (STAGE 2):
```
âœ“ Stage 2 complete
Best validation accuracy: 0.9456
```

### After Cell 14 (Validation):
```
Overall Accuracy: 0.9456 (94.56%)

              precision  recall  f1-score  support
         A       0.9234  0.9123   0.9178      120
         B       0.8901  0.9012   0.8956      118
        ...
    accuracy                      0.9456     3254
```

### After Cell 15 (Confusion Matrix):
- Visual heatmap showing which letters are confused
- Diagonal = correct predictions (should be high)
- Off-diagonal = errors (should be low)

### After Cell 16 (Model Save):
```
âœ“ Model saved (H5): models/asl_alphabet_model.h5
  File size: 24.35 MB
âœ“ Labels saved: models/labels.json
âœ“ Training config saved: models/training_config.json
âœ“ Model summary saved: models/model_summary.txt
```

### After Cell 20 (Summary):
```
âœ“ MODEL ARTIFACTS:
  âœ“ asl_alphabet_model.h5        â†’ Keras model
  âœ“ saved_model/                 â†’ TensorFlow SavedModel
  âœ“ labels.json                  â†’ Class labels
  âœ“ training_history.png         â†’ Accuracy/Loss curves
  âœ“ confusion_matrix.png         â†’ Per-class performance
  âœ“ evaluation_results.json      â†’ Validation metrics

âœ… PRODUCTION NOTEBOOK READY FOR DEPLOYMENT
```

---

## ğŸ’¡ Pro Tips

### 1. Save Outputs Regularly
- After each training stage, outputs are auto-saved to `models/`
- Download before restarting kernel

### 2. Pause Between Stages
```
After Cell 12 (training completes):
- Save checkpoint
- Review training curves (Cell 13)
- Check metrics before fine-tuning
```

### 3. Use VS Code Built-in Features
- **Outline** (Ctrl+Shift+O): Jump to any cell
- **Go to Line** (Ctrl+G): Jump to specific line
- **Search** (Ctrl+F): Find text in notebook

### 4. Monitor Progress
- **Terminal** (Ctrl+`): Open to watch system resources
- **Variables** panel: See global variables after each cell
- **Output panel**: Scroll through results

### 5. Save Notebook State
- Auto-saves in VS Code
- Manual save: Ctrl+S
- Checkpoints preserved in `models/` directory

---

## ğŸ¯ Quick Checklist

Before running:
- [ ] Notebook file exists: `notebooks/1_ASL_Alphabet_Dataset.ipynb`
- [ ] Python kernel selected: Python 3.12.12
- [ ] Kaggle dataset ready (or will download)
- [ ] At least 10GB disk space free
- [ ] For training: CPU/GPU with 6GB+ RAM

While running:
- [ ] Don't close VS Code or terminal
- [ ] Monitor output for errors
- [ ] Save model files after training completes

After running:
- [ ] Check `models/` directory for output files
- [ ] Review training plots and confusion matrix
- [ ] Next step: Convert to TFJS and deploy

---

## ğŸš€ Next Steps After Training

1. **TFJS Conversion** (local machine)
   ```bash
   pip install tensorflowjs
   tensorflowjs_converter --input_format=tf_saved_model \
     models/saved_model models/tfjs
   ```

2. **Copy to Web App**
   ```
   Copy models/tfjs/* â†’ public/tfjs/asl_model/
   Copy models/labels.json â†’ data/models/labels.json
   ```

3. **Test in Browser**
   - Open web app at `localhost:3000`
   - Go to `/recognize` page
   - Test real-time gesture recognition

---

## ğŸ“ Support

If you encounter issues:
1. Check **NOTEBOOKS_GUIDE.md** for detailed explanations
2. Review **COLAB_QUICK_START.md** for Colab-specific help
3. Check **NOTEBOOK_COMPLETION.md** for deployment info

---

**Status: âœ… Ready to Train**

Your notebook is properly configured and ready to run in VS Code.
Choose your execution method above and start training! ğŸ‰
